{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Utils.UtilsViz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the data files provided?\n",
    "data_path = os.path.join(os.getcwd(), \"datasets\")\n",
    "projects_data = pd.read_csv(os.path.join(data_path, \"projects.csv\"), nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Projects data -->  (664098, 35)\nColumns : \n\t projectid\n\t teacher_acctid\n\t schoolid\n\t school_ncesid\n\t school_latitude\n\t school_longitude\n\t school_city\n\t school_state\n\t school_zip\n\t school_metro\n\t school_district\n\t school_county\n\t school_charter\n\t school_magnet\n\t school_year_round\n\t school_nlns\n\t school_kipp\n\t school_charter_ready_promise\n\t teacher_prefix\n\t teacher_teach_for_america\n\t teacher_ny_teaching_fellow\n\t primary_focus_subject\n\t primary_focus_area\n\t secondary_focus_subject\n\t secondary_focus_area\n\t resource_type\n\t poverty_level\n\t grade_level\n\t fulfillment_labor_materials\n\t total_price_excluding_optional_support\n\t total_price_including_optional_support\n\t students_reached\n\t eligible_double_your_impact_match\n\t eligible_almost_home_match\n\t date_posted\n\n"
     ]
    }
   ],
   "source": [
    "print(\" Projects data --> \", projects_data.shape)\n",
    "print_df_cols(projects_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the Project dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = projects_data[\"projectid\"].unique()\n",
    "print(\"Total number of project IDs :\", project_list.shape[0])\n",
    "\n",
    "school_list =  projects_data[\"schoolid\"].unique()\n",
    "print(\"Total number of School IDs :\", school_list.shape[0])\n",
    "\n",
    "school_county_list =  projects_data[\"school_county\"].unique()\n",
    "print(\"Total number of School Counties :\", school_county_list.shape[0])\n",
    "\n",
    "resource_type_list =  projects_data[\"resource_type\"].unique()\n",
    "print(\"Total number of Resource Types :\", resource_type_list.shape[0], resource_type_list)\n",
    "\n",
    "poverty_level_list =  projects_data[\"poverty_level\"].unique()\n",
    "print(\"Total number of Poverty Levels :\", poverty_level_list.shape[0], poverty_level_list)\n",
    "\n",
    "grade_level_list =  projects_data[\"grade_level\"].unique()\n",
    "print(\"Total number of Grade Levels :\", grade_level_list.shape[0], grade_level_list)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Let's visualise the data in choropleth maps.\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Concentration of schools in counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we declare some helper variables and get the GEOJSON data for the counties.\n",
    "# Get the path of the GeoJSON file for the chiorpleth map\n",
    "_path = os.getcwd()\n",
    "county_geojson_fpath = \"D:/Dev/Sources/Projects/GitProjects/KDDCup_2014/res/gz_2010_us_050_00_500k.json\"\n",
    "# NOTE : the key to look for in the json file is 'feature.properties.NAME'\n",
    "US_coord = [37.0902, -102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_schoolconc_data = projects_data[[\"school_county\", \"schoolid\"]].groupby(by=\"school_county\", as_index=False).count()\n",
    "th_scale = get_th_scale(data=county_schoolconc_data, col=\"schoolid\", n_steps=4)\n",
    "# Draw the map and visualise\n",
    "map1 = draw_choropleth_map(json_path=county_geojson_fpath, json_key='feature.properties.NAME',\n",
    "                           threshold_scale=th_scale, start_coord=US_coord,\n",
    "                          data=county_schoolconc_data, data_cols=list(county_schoolconc_data.columns),\n",
    "                          legend_name=\"Number of schools per county\")\n",
    "open_map_in_browser(geomap=map1, path=os.path.join(\"D:/Dev/Sources/Projects/GitProjects/KDDCup_2014/res/\", 'school_conc.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  schoolid  students_reached\nschoolid              1.00              0.97\nstudents_reached      0.97              1.00\n"
     ]
    }
   ],
   "source": [
    "# Is there a correlation between students reached in a county and number of schools in a county?\n",
    "county_stdreach_data = projects_data[[\"school_county\", \"students_reached\"]].groupby(by=\"school_county\", as_index=False).sum()\n",
    "county_sc_sr_data = pd.merge(left=county_schoolconc_data, right=county_stdreach_data, on=\"school_county\")\n",
    "print(np.round(county_sc_sr_data.corr(), 2))\n",
    "# Very high correlation there. It's safe to say that we do not need to make a separate choropleth map for students "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Python36\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Encode the categorical data poverty level \n",
    "temp_df = projects_data[[\"school_county\", \"poverty_level\"]]\n",
    "categories = {\n",
    "    'highest poverty':3,\n",
    "    'high poverty':2,\n",
    "    'moderate poverty':1,\n",
    "    'low poverty':0\n",
    "}\n",
    "def set_category(val):\n",
    "    return categories[val]\n",
    "temp_df[\"poverty_level\"] = temp_df.apply(lambda row: set_category(row[\"poverty_level\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_schpoverty_data = temp_df.groupby(by=\"school_county\", as_index=False).mean()\n",
    "county_schpoverty_data[\"poverty_level\"] = county_schpoverty_data[\"poverty_level\"]*100\n",
    "county_schpoverty_data[\"poverty_level\"] = county_schpoverty_data[\"poverty_level\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64558408.0\n"
     ]
    }
   ],
   "source": [
    "# How many students did this program reach?\n",
    "print(projects_data[\"students_reached\"].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are all the commonly named columns present in each dataset? \n",
    "\n",
    "# all_cols = []\n",
    "# all_cols.append(list(donations_data.columns))\n",
    "# all_cols.append(list(resources_data.columns))\n",
    "# all_cols.append(list(projects_data.columns))\n",
    "# common_cols = find_common_cols(all_cols)\n",
    "# print(common_cols)\n",
    "\n",
    "# This really works well with the metadata provided. We can join these datasets with the project ID to make one consolidated dataset\n",
    "\n",
    "# d_p_data = pd.merge(donations_data, projects_data, how='inner', on=\"projectid\")\n",
    "\n",
    "# consolidated_data = pd.merge(d_p_data, resources_data, how='inner', on=\"projectid\")\n",
    "\n",
    "# consolidated_data.shape\n",
    "\n",
    "# donations_data.head()\n",
    "\n",
    "\n",
    "# donations_data.projectid.value_counts(ascending=False)\n",
    "\n",
    "# # Cleaning\n",
    "\n",
    "# # Find rows with NaNs\n",
    "# nan_row_cnt = donations_data.dropna().shape[0]\n",
    "# print(\"Number of rows with NaNs in them :\", nan_row_cnt)\n",
    "# print(\"\\t in percentage :\", nan_row_cnt / donations_data.shape[0])\n",
    "# # Clearly dropping them all blindly is NOT the best solution. \n",
    "\n",
    "\n",
    "\n",
    "# # What about the categorical variables?\n",
    "# cities = donations_data[\"donor_city\"].unique()\n",
    "# print(\"Number of cities : \", cities.shape[0])\n",
    "\n",
    "# states = donations_data[\"donor_state\"].unique()\n",
    "# print(\"Number of states : \", states.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
